---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a third-year Ph.D. candidate at the Institute of Artificial Intelligence and Robotics ([IAIR](https://iair.xjtu.edu.cn/index.htm), Xi'an Jiaotong University (XJTU), where I pursue my doctoral studies under the supervision of Prof.[Le Wang](https://gr.xjtu.edu.cn/web/lewang). I also collaborate closely with Prof.[Sanping Zhou](https://gr.xjtu.edu.cn/web/spzhou), Prof.[Gang Hua](https://www.ganghua.org/) and Prof.[Wei Tang](https://www.cs.uic.edu/~tangw/).
 
I am currently a visiting Ph.D. student with the Multimedia and Human Understanding Group (MHUG) at the University of Trento, under the supervision of [Nicu Sebe](https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en).




# ğŸ”¥ News {#news}
- *2025.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2026.
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACM MM 2025.
- *2025.03*: &nbsp;ğŸ‰ğŸ‰ Two paper is accepted by CVPR 2025.
- *2024.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2025.
- *2024.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACM MM 2024.
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by NIPS 2024.
- *2024.02*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by TIP.
- *2023.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2024.
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACM MM 2022.
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by TCSVT.




# ğŸ“ Selected Publications {#selectedpublications}
<div class='paper-box'>
  <div class='paper-box-image'>
    <div class="badge pulse-accent">Visual Grounding</div>
    <img src='images/nips2024.png' alt="SAMPO" width="100%">
  </div>
  <div class='paper-box-text'>
    <h3>Referencing Where to Focus: Improving Visual Grounding with Referential Query</h3>
    <div class="authors">
      <strong>Yabing Wang<strong>, Zhuotao Tian, Qingpei Guo, Zheng Qin, Sanping Zhou, Ming Yang, Le Wang
    </div>
    <div class="venue">NIPS24</div>
    <div class="links">
      <!-- <a href="https://www.youtube.com/watch?v=HaS9cM75J7Y" class="btn-accent">Video</a> -->
      <a href="https://arxiv.org/abs/2412.19155" class="btn-accent"><i class="fas fa-file-alt"></i> Paper</a>
      <a href="https://github.com/LiJiaBei-7/RefFormer" class="btn-accent"><i class="fab fa-github"></i> Code</a>
    </div>
  </div>
</div>




# Publications  {#publications}

- Referencing Where to Focus: Improving Visual Grounding with Referential Query (NeurIPS 2024)  
  Wang Y, Tian Z, Guo Q, **Qin Z**, Zhou S, Yang M, Wang L.

- RefDetector: A Simple yet Effective Matching-based Method for Referring Expression Comprehension (AAAI 2025)  
  Wang Y, Tian Z, **Qin Z**, Zhou S, Wang L.

- Towards Precise Embodied Dialogue Localization via Causality Guided Diffusion (CVPR 2025)  
  Wang H, Wang L, **Qin Z**, Wang Y, Hua G, Tang W.

- Versatile Multimodal Controls for Whole-Body Talking Human Animation (ACM MM 2025)  
  **Qin Z**, Zheng R, Wang Y, Li T, Zhu Z, Yang M, Yang M, Wang L.

- HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs (AAAI 2026)  
  **Qin Z**, Zheng R, Wang Y, Li T, Yuan Y, Chen J, Wang L.

- Single-Shot and Multi-Shot Feature Learning for Multi-Object Tracking (TMM 2024)  
  Li Y, Zhou S, **Qin Z**, Wang L, Wang J, Zheng N.

- Robust Noisy Label Learning via Two-Stream Sample Distillation (TMM 2025)  
  Bai S, Zhou S, **Qin Z**, Wang L, Zheng N.

- Semantic and Kinematics Guidance for RMOT (TMM 2025)  
  Li Y, Zhou S, **Qin Z**, Wang L.

- Injecting Position and Relation Prior for Dense Video Captioning (Submitted to TIP)  
  Li Y, Zhou S, **Qin Z**, Lin J, Sun X, Wu K, Wang L.

- From Mapping to Composing: A Two-Stage Framework for Zero-shot Composed Image Retrieval (Submitted to TCSVT)  
  Wang Y, Tian Z, Guo Q, **Qin Z**, Zhou S, Yang M, Wang L.

- Embracing Aleatoric Uncertainty: Generating Diverse 3D Human Motion (Submitted to TCSVT)  
  **Qin Z**, Wang L, Wang Y, Yang M, Rong C, Yang M, Zheng N.

- RSRNav: Reasoning Spatial Relationship for Image-Goal Navigation (Submitted to TCSVT)  
  **Qin Z**, Wang L, Wang Y, Zhou S, Hua G, Tang W.

- Spatial Matters: Position-Guided 3D Referring Expression Segmentation (Submitted to CVPR 2026)  
  Wang Y, Tian Z, Wang L, **Qin Z**, Zhou S.

# ğŸ“– Educations {#educations}
- *2025.09 - now*, Visiting Ph.D. student, Artificial Intelligence, University of Trento.
- *2023.09 - now*, Ph.D. student, Control Science and Engineering, Xi'an Jiaotong University. 


# ğŸ’» Internships {#internships}
- *2024.05 - 2025.07*, Ant Group, Bailing Large Model Team | Research Intern


# ğŸ– Honors and Scholarships {#honors-and-scholarships}
- **National Scholarship (PhD)**, 2025  
- **Yidong PhD)**, 2024  


# ğŸ’¬ Invited Talks {#invited-talks}
- *2024.07*, Invited to present the paper at the â€œSummer of the Institute of Humanâ€“Computer Interaction, XJTUâ€

# Services {#services}
Reviewer for CVPR, ICCV, ICML, ECCV, ICLR, NIPS, ACM MM, AAAI, TIP, TMM, PR, etc.

